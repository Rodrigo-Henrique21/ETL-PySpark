{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23388d2e-f760-420f-9ae7-d01835f27638",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configurações inicias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60da12e7-8f93-4ee1-bb2c-fc1c2167fc2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'Spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-27eca23f3d7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m###### CRIACAO DA SESSAO SPARK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m###############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m spark = Spark(\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0msession_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mSESSION_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0mENV_VAR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"KEYTAB\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Spark' is not defined"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "###### IMPORTACAO\n",
    "###############################################################################\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "###############################################################################\n",
    "###### CONFIGURACOES PARAMETROS PARA INICIAR SESSAO SPARK\n",
    "###############################################################################\n",
    "HDP_VERSION = 3  # type: int\n",
    "SESSION_NAME = \"HEDGE\"  # type: str\n",
    "LANGUAGE = \"python\"\n",
    "\n",
    "####### Constantes que definem os valores para dimensionamento da sessao spark no yarn\n",
    "\n",
    "\n",
    "DRIVER_MEMORY = \"32g\",\n",
    "DRIVER_CORES = 8,\n",
    "EXECUTOR_CORES = 16,\n",
    "EXECUTOR_MEMORY = \"32g\",\n",
    "SPARK_CONF = {\n",
    "\"spark.dynamicAllocation.enabled\": \"true\",\n",
    "\"spark.dynamicAllocation.minExecutors\" : \"16\",\n",
    "\"spark.dynamicAllocation.maxExecutors\" : \"30\",\n",
    "\"spark.dynamicAllocation.initialExecutors\" : \"16\",\n",
    "\"spark.dynamicAllocation.schedulerBacklogTimeout\" : \"2m\",\n",
    "\"spark.dynamicAllocation.executorIdleTimeout\": \"120s\",\n",
    "\"spark.shuffle.service.enabled\": \"true\",\n",
    "\"spark.driver.memoryOverhead\" : \"16g\",\n",
    "\"spark.executor.memoryOverhead\" : \"16g\",\n",
    "\"spark.sql.sources.partitionOverwriteMode\": \"dynamic\",\n",
    "\"spark.sql.hive.caseSensitiveInferenceMode\": \"NEVER_INFER\",\n",
    "\"spark.shuffle.service.enabled\": \"true\", \n",
    "\"spark.shuffle.service.port\": \"7447\", \n",
    "\"spark.shuffle.service.name\": \"spark2_shuffle\", \n",
    "\"spark.shuffle.useOldFetchProtocol\": \"true\",\n",
    "\"spark.shuffle.sort.bypassMergeThreshold\": \"40\",\n",
    "\"spark.sql.inMemoryColumnarStorage.compressed\": \"true\",\n",
    "\"spark.sql.inMemoryColumnarStorage.batchSize\": \"10000\"\n",
    "}\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###### CONSTANTE QUE SERVE PARA DEFINIR PARAMETROS A SEREM UTILIZADOS CONFORME \n",
    "###### AMBIENTE (MODELAGEM OU SCORAGE/PRODUCAO) NO QUAL O JOB SERA EXECUTADO \n",
    "###############################################################################\n",
    "AMBIENTE = os.environ[\"AMBIENTE\"] \n",
    "if AMBIENTE == \"MODELAGEM\":\n",
    "    ENV_VAR = {\n",
    "        \"OWNER_D4F\":\"\",\n",
    "        \"TABELA_ENTRADA\":\"\",\n",
    "        \"AMBIENTE\":AMBIENTE,\n",
    "        \"TABLE_DB2_DOMINIO\":\"\",\n",
    "        \"KEYTAB\": \"\"\n",
    "    }\n",
    "    !kdestroy\n",
    "else:\n",
    "    ENV_VAR = {\n",
    "        \"OWNER_D4F\":\"\",\n",
    "        \"TABELA_ENTRADA\":\"\",\n",
    "        \"TABLE_DB2_DOMINIO\":\"\",\n",
    "        \"KEYTAB\": os.environ['KEYTAB']\n",
    "    }\n",
    "    \n",
    "###############################################################################\n",
    "###### CRIACAO DA SESSAO SPARK \n",
    "###############################################################################\n",
    "spark = Spark(\n",
    "    session_name= SESSION_NAME, \n",
    "    username=  ENV_VAR[\"KEYTAB\"], \n",
    "    hdp = HDP_VERSION,\n",
    "    language = LANGUAGE,\n",
    "    db2=True,\n",
    "    spark_conf=SPARK_CONF,\n",
    "    auth = 'Kerberos',\n",
    "    env = ENV_VAR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a7305ca1-9d6a-4ad0-b114-6f29d8c01f88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, column, expr, when\n",
    "from pyspark.sql.types import DecimalType, DateType, DoubleType, IntegerType, LongType, ShortType, StringType, StructField, StructType,TimestampType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be02f24a-5772-4b27-a32a-1c812b38fda6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MontaConsultasDB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "da936713-0fa1-475e-9f35-5164b03915ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "def MontaQuery(key):\n",
    "    \n",
    "    cd_mtdl_e = 15\n",
    "    cd_rgr_e = 225\n",
    "    gda_nr_crit_rech = 0\n",
    "    gda_seql_crit_rech = 0\n",
    "   \n",
    "    if key == 1:\n",
    "        \n",
    "        query_psqC1 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        A.IN_RGR_ATV,\n",
    "        B.CD_CRIT_INRO,\n",
    "        B.NR_SEQL_CRIT_INRO,\n",
    "        B.CD_TIP_CTU,\n",
    "        B.TX_CTU,\n",
    "        B.IN_CRIT_ATI\n",
    "        FROM\n",
    "        \"\".RGR_INRO_MTDL AS A,\n",
    "        \"\".CMPS_RGR_INRO AS B\n",
    "        WHERE\n",
    "        A.CD_MTDL_ANL_CRD = {0}\n",
    "        AND A.CD_RGR_INRO = {1}\n",
    "        AND B.CD_MTDL_ANL_CRD = A.CD_MTDL_ANL_CRD\n",
    "        AND B.CD_RGR_INRO = A.CD_RGR_INRO\n",
    "        AND ((B.CD_CRIT_INRO >= {2}\n",
    "            AND B.NR_SEQL_CRIT_INRO > {3} )\n",
    "        OR (B.CD_CRIT_INRO > {2} ))\n",
    "        AND B.NR_SEQL_CMPS = (\n",
    "        SELECT\n",
    "        MAX (C.NR_SEQL_CMPS)\n",
    "        FROM\n",
    "        \"\".CMPS_RGR AS C\n",
    "        WHERE\n",
    "        C.CD_MTDL_ANL_CRD = {0}\n",
    "        AND C.CD_RGR_INRO = {1}\n",
    "        AND C.TS_INC_VGC <> '0001-01-01-00.00.00.000000')\n",
    "        ORDER BY\n",
    "        B.IN_CRIT_ATI DESC,\n",
    "        B.CD_CRIT_INRO ,\n",
    "        B.NR_SEQL_CRIT_INRO\n",
    "        --FETCH FIRST 72 ROWS ONLY\n",
    "         ) as query_psqC1\n",
    "         \"\"\".format(cd_mtdl_e,cd_rgr_e,gda_nr_crit_rech,gda_seql_crit_rech)\n",
    "\n",
    "\n",
    "        query_psqC1 = spark.read.format(\"jdbc\") \\\n",
    "                                .option(\"URL\",URL) \\\n",
    "                                .option(\"driver\",JCN) \\\n",
    "                                .option(\"dbtable\",query_psqC1) \\\n",
    "                                .option(\"user\",DB2_USER) \\\n",
    "                                .option(\"password\",DB2_PASSWORD) \\\n",
    "                                .option('KeepAliveTimeout','10') \\\n",
    "                                .load()\n",
    "           \n",
    "        return query_psqC1\n",
    "    \n",
    "    elif key == 2:\n",
    "        query_psqC2 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        A.IN_RGR_ATV,\n",
    "        B.NR_SEQL_CMPS,\n",
    "        B.NR_SEQL_CRIT_INRO,\n",
    "        B.CD_TIP_CTU,\n",
    "        B.TX_CTU,\n",
    "        B.IN_CRIT_ATI\n",
    "        FROM\n",
    "        \"\".RGR_INRO_MTDL AS A,\n",
    "        \"\".CMPS_RGR_INRO AS B\n",
    "        WHERE\n",
    "        A.CD_MTDL_ANL_CRD = {0}\n",
    "        AND A.CD_RGR_INRO = {1}\n",
    "        AND B.CD_MTDL_ANL_CRD = A.CD_MTDL_ANL_CRD\n",
    "        AND B.CD_RGR_INRO = A.CD_RGR_INRO\n",
    "        AND B.CD_CRIT_INRO = {2}\n",
    "        AND B.NR_SEQL_CMPS = (\n",
    "        SELECT\n",
    "            MAX (C.NR_SEQL_CMPS)\n",
    "        FROM\n",
    "            \"\".CMPS_RGR AS C\n",
    "        WHERE\n",
    "            C.CD_MTDL_ANL_CRD = A.CD_MTDL_ANL_CRD\n",
    "            AND C.CD_RGR_INRO = A.CD_RGR_INRO\n",
    "            AND C.TS_INC_VGC <> '0001-01-01-00.00.00.000000')\n",
    "        ORDER BY\n",
    "        B.NR_SEQL_CRIT_INRO\n",
    "        --FETCH FIRST 72 ROWS ONLY\n",
    "        ) as query_psqC2\n",
    "        \"\"\".format(aux_cd_mtdl,aux_cd_rgr,cd_crit_e)\n",
    "        \n",
    "        query_psqC2 =    spark.read.format(\"jdbc\") \\\n",
    "                                 .option(\"URL\",URL) \\\n",
    "                                 .option(\"driver\",JCN) \\\n",
    "                                 .option(\"dbtable\",query_psqC2) \\\n",
    "                                 .option(\"user\",DB2_USER) \\\n",
    "                                 .option(\"password\",DB2_PASSWORD) \\\n",
    "                                 .option('KeepAliveTimeout','10') \\\n",
    "                                 .load()\n",
    "    \n",
    "        return query_psqC2\n",
    "    \n",
    "    elif key == 3:\n",
    "        \n",
    "        query_psqC3 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        A.IN_RGR_ATV,\n",
    "        B.CD_CRIT_INRO,\n",
    "        B.NR_SEQL_CRIT_INRO,\n",
    "        B.CD_TIP_CTU,\n",
    "        B.TX_CTU,\n",
    "        B.IN_CRIT_ATI\n",
    "        FROM\n",
    "        \"\".RGR_INRO_MTDL AS A,\n",
    "        \"\".CMPS_RGR_INRO AS B,\n",
    "        \"\".CMPS_RGR AS C\n",
    "        WHERE\n",
    "        A.CD_MTDL_ANL_CRD = {0}\n",
    "        AND A.CD_RGR_INRO = {1}\n",
    "        AND B.CD_MTDL_ANL_CRD = A.CD_MTDL_ANL_CRD\n",
    "        AND B.CD_RGR_INRO = A.CD_RGR_INRO\n",
    "        AND C.CD_MTDL_ANL_CRD = A.CD_MTDL_ANL_CRD\n",
    "        AND C.CD_RGR_INRO = A.CD_RGR_INRO\n",
    "        AND C.NR_SEQL_CMPS = B.NR_SEQL_CMPS\n",
    "        AND C.TS_INC_VGC = '0001-01-01-00.00.00.000000'\n",
    "        AND ((B.CD_CRIT_INRO >= {2}\n",
    "            AND B.NR_SEQL_CRIT_INRO > {2} )\n",
    "        OR (B.CD_CRIT_INRO > {2} ))\n",
    "        GROUP BY\n",
    "        A.IN_RGR_ATV,\n",
    "        B.CD_CRIT_INRO,\n",
    "        B.NR_SEQL_CRIT_INRO,\n",
    "        B.CD_TIP_CTU,\n",
    "        B.TX_CTU,\n",
    "        B.IN_CRIT_ATI\n",
    "        ORDER BY\n",
    "        B.CD_CRIT_INRO ,\n",
    "        B.NR_SEQL_CRIT_INRO\n",
    "        --FOR FETCH ONLY\n",
    "        ) as query_psqC3\n",
    "        \"\"\".format(aux_cd_mtdl,aux_cd_rgr,cd_crit_e)\n",
    "\n",
    "        query_psqC3 =    spark.read.format(\"jdbc\") \\\n",
    "                                 .option(\"URL\",URL) \\\n",
    "                                 .option(\"driver\",JCN) \\\n",
    "                                 .option(\"dbtable\",query_psqC3) \\\n",
    "                                 .option(\"user\",DB2_USER) \\\n",
    "                                 .option(\"password\",DB2_PASSWORD) \\\n",
    "                                 .option('KeepAliveTimeout','10') \\\n",
    "                                 .load()\n",
    "    \n",
    "        return query_psqC3\n",
    "    \n",
    "    \n",
    "    elif key == 4:\n",
    "        \n",
    "        query_psqC4 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        COUNT(*) AS CONTAGEM_GERAL\n",
    "        FROM\n",
    "        \"\".CMPS_RGR A\n",
    "        WHERE\n",
    "        A.CD_MTDL_ANL_CRD = {0}\n",
    "        AND A.CD_RGR_INRO = {1}\n",
    "        AND A.TS_INC_VGC = '0001-01-01-00.00.00.000000'\n",
    "        ) as query_psqC4\n",
    "        \"\"\".format(aux_cd_mtdl,aux_cd_rgr)\n",
    "\n",
    "        query_psqC4 =    spark.read.format(\"jdbc\") \\\n",
    "                                 .option(\"URL\",URL) \\\n",
    "                                 .option(\"driver\",JCN) \\\n",
    "                                 .option(\"dbtable\",query_psqC4) \\\n",
    "                                 .option(\"user\",DB2_USER) \\\n",
    "                                 .option(\"password\",DB2_PASSWORD) \\\n",
    "                                 .option('KeepAliveTimeout','10') \\\n",
    "                                 .load()\n",
    "    \n",
    "        return query_psqC4\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    elif key == 5:\n",
    "        \n",
    "        query_psqC5 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        DISTINCT CD_MTDL_ANL_CRD\n",
    "        FROM\n",
    "        \"\".CMPS_RGR_INRO\n",
    "        WHERE\n",
    "        CD_MTDL_ANL_CRD > {0}\n",
    "        ORDER BY\n",
    "        CD_MTDL_ANL_CRD\n",
    "        ) as query_psqC5\n",
    "        \"\"\".format(aux_cd_mtdl)\n",
    "\n",
    "        query_psqC5 =    spark.read.format(\"jdbc\") \\\n",
    "                                 .option(\"URL\",URL) \\\n",
    "                                 .option(\"driver\",JCN) \\\n",
    "                                 .option(\"dbtable\",query_psqC5) \\\n",
    "                                 .option(\"user\",DB2_USER) \\\n",
    "                                 .option(\"password\",DB2_PASSWORD) \\\n",
    "                                 .option('KeepAliveTimeout','10') \\\n",
    "                                 .load()\n",
    "    \n",
    "        return query_psqC5\n",
    "    \n",
    "    \n",
    "    elif key == 6:\n",
    "        \n",
    "        query_psqC6 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        DISTINCT A.CD_MTDL_ANL_CRD\n",
    "        FROM\n",
    "        \"\".CMPS_RGR_INRO A,\n",
    "        \"\".CMPS_RGR B\n",
    "        WHERE\n",
    "        A.CD_MTDL_ANL_CRD > {0}\n",
    "        AND A.CD_MTDL_ANL_CRD = B.CD_MTDL_ANL_CRD\n",
    "        AND A.CD_RGR_INRO = B.CD_RGR_INRO\n",
    "        AND A.NR_SEQL_CMPS = B.NR_SEQL_CMPS\n",
    "        AND A.NR_SEQL_CMPS = (\n",
    "        SELECT\n",
    "            MAX (C.NR_SEQL_CMPS)\n",
    "        FROM\n",
    "            \"\".CMPS_RGR C\n",
    "        WHERE\n",
    "            C.CD_MTDL_ANL_CRD = A.CD_MTDL_ANL_CRD\n",
    "            AND C.CD_RGR_INRO = A.CD_RGR_INRO )\n",
    "        AND B.TS_INC_VGC <> '0001-01-01-00.00.00.000000'\n",
    "        ORDER BY\n",
    "        A.CD_MTDL_ANL_CRD\n",
    "        ) as query_psqC6\n",
    "        \"\"\".format(aux_cd_mtdl)\n",
    "\n",
    "        query_psqC6 =    spark.read.format(\"jdbc\") \\\n",
    "                                 .option(\"URL\",URL) \\\n",
    "                                 .option(\"driver\",JCN) \\\n",
    "                                 .option(\"dbtable\",query_psqC6) \\\n",
    "                                 .option(\"user\",DB2_USER) \\\n",
    "                                 .option(\"password\",DB2_PASSWORD) \\\n",
    "                                 .option('KeepAliveTimeout','10') \\\n",
    "                                 .load()\n",
    "    \n",
    "        return query_psqC6\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif key == 7:\n",
    "        \n",
    "        query_psqC7 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        DISTINCT CD_MTDL_ANL_CRD\n",
    "        FROM\n",
    "        \"\".CMPS_RGR\n",
    "        WHERE\n",
    "        CD_MTDL_ANL_CRD > {0}\n",
    "        AND TS_INC_VGC = '0001-01-01-00.00.00.000000'\n",
    "        ORDER BY\n",
    "        CD_MTDL_ANL_CRD\n",
    "        ) as query_psqC7\n",
    "        \"\"\".format(aux_cd_mtdl)\n",
    "\n",
    "        query_psqC7 =    spark.read.format(\"jdbc\") \\\n",
    "                                 .option(\"URL\",URL) \\\n",
    "                                 .option(\"driver\",JCN) \\\n",
    "                                 .option(\"dbtable\",query_psqC7) \\\n",
    "                                 .option(\"user\",DB2_USER) \\\n",
    "                                 .option(\"password\",DB2_PASSWORD) \\\n",
    "                                 .option('KeepAliveTimeout','10') \\\n",
    "                                 .load()\n",
    "    \n",
    "        return query_psqC7\n",
    "    \n",
    "    \n",
    "    elif key == 8:\n",
    "        \n",
    "        query_psqC8 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        DISTINCT A.CD_MTDL_ANL_CRD\n",
    "        FROM\n",
    "        \"\".CMPS_RGR_INRO A,\n",
    "        \"\".CMPS_RGR B\n",
    "        WHERE\n",
    "        A.CD_MTDL_ANL_CRD > {0}\n",
    "        AND A.CD_MTDL_ANL_CRD = B.CD_MTDL_ANL_CRD\n",
    "        AND A.CD_RGR_INRO = B.CD_RGR_INRO\n",
    "        AND A.NR_SEQL_CMPS = B.NR_SEQL_CMPS\n",
    "        AND A.NR_SEQL_CMPS <> (\n",
    "        SELECT\n",
    "            MAX (C.NR_SEQL_CMPS)\n",
    "        FROM\n",
    "            \"\".CMPS_RGR C\n",
    "        WHERE\n",
    "            C.CD_MTDL_ANL_CRD = A.CD_MTDL_ANL_CRD\n",
    "            AND C.CD_RGR_INRO = A.CD_RGR_INRO)\n",
    "        AND B.TS_INC_VGC <> '0001-01-01-00.00.00.000000'\n",
    "        ORDER BY\n",
    "        A.CD_MTDL_ANL_CRD\n",
    "        ) as query_psqC8\n",
    "        \"\"\".format(aux_cd_mtdl)\n",
    "\n",
    "        query_psqC8 =    spark.read.format(\"jdbc\") \\\n",
    "                                 .option(\"URL\",URL) \\\n",
    "                                 .option(\"driver\",JCN) \\\n",
    "                                 .option(\"dbtable\",query_psqC8) \\\n",
    "                                 .option(\"user\",DB2_USER) \\\n",
    "                                 .option(\"password\",DB2_PASSWORD) \\\n",
    "                                 .option('KeepAliveTimeout','10') \\\n",
    "                                 .load()\n",
    "    \n",
    "        return query_psqC8\n",
    "    \n",
    "    \n",
    "    elif key == 9:\n",
    "        \n",
    "        query_psqC9 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        A.IN_RGR_ATV,\n",
    "        B.CD_CRIT_INRO,\n",
    "        B.NR_SEQL_CRIT_INRO,\n",
    "        B.CD_TIP_CTU,\n",
    "        B.TX_CTU,\n",
    "        B.IN_CRIT_ATI\n",
    "        FROM\n",
    "        \"\".RGR_INRO_MTDL AS A,\n",
    "        \"\".CMPS_RGR_INRO AS B\n",
    "        WHERE\n",
    "        A.CD_MTDL_ANL_CRD = {0}\n",
    "        AND A.CD_RGR_INRO = {1}\n",
    "        AND B.CD_MTDL_ANL_CRD = A.CD_MTDL_ANL_CRD\n",
    "        AND B.CD_RGR_INRO = A.CD_RGR_INRO\n",
    "        AND ((B.CD_CRIT_INRO >= {2}\n",
    "            AND B.NR_SEQL_CRIT_INRO > {3})\n",
    "        OR (B.CD_CRIT_INRO > {2}))\n",
    "        AND B.NR_SEQL_CMPS = (\n",
    "        SELECT\n",
    "            MAX (C.NR_SEQL_CMPS)\n",
    "        FROM\n",
    "            \"\".CMPS_RGR AS C\n",
    "        WHERE\n",
    "            C.CD_MTDL_ANL_CRD = {0}\n",
    "            AND C.CD_RGR_INRO = {1}\n",
    "            AND C.TS_INC_VGC <> '0001-01-01-00.00.00.000000')\n",
    "        AND A.IN_RGR_ATV = 'S'\n",
    "        AND B.IN_CRIT_ATI = 'S'\n",
    "        ORDER BY\n",
    "        B.CD_CRIT_INRO,\n",
    "        B.NR_SEQL_CRIT_INRO\n",
    "        --FETCH FIRST 72 ROWS ONLY\n",
    "        ) as query_psqC9\n",
    "        \"\"\".format(cd_mtdl_e,cd_rgr_e,gda_nr_crit_rech,gda_seql_crit_rech)\n",
    "\n",
    "        query_psqC9 =    spark.read.format(\"jdbc\") \\\n",
    "                                 .option(\"URL\",URL) \\\n",
    "                                 .option(\"driver\",JCN) \\\n",
    "                                 .option(\"dbtable\",query_psqC9) \\\n",
    "                                 .option(\"user\",DB2_USER) \\\n",
    "                                 .option(\"password\",DB2_PASSWORD) \\\n",
    "                                 .option('KeepAliveTimeout','10') \\\n",
    "                                 .load()\n",
    "    \n",
    "        return query_psqC9\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif key == 10:\n",
    "        \n",
    "        query_psqC10 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        MAX (A.NR_SEQL_CRIT_INRO) AS NR_SEQL_CRIT_INRO\n",
    "        FROM\n",
    "        \"\".CMPS_RGR_INRO A,\n",
    "        \"\".CMPS_RGR B\n",
    "        WHERE\n",
    "        A.CD_MTDL_ANL_CRD = {0}\n",
    "        AND A.CD_MTDL_ANL_CRD = B.CD_MTDL_ANL_CRD\n",
    "        AND A.CD_RGR_INRO = {1}\n",
    "        AND A.CD_RGR_INRO = B.CD_RGR_INRO\n",
    "        AND A.CD_CRIT_INRO = {2}\n",
    "        AND A.NR_SEQL_CMPS = B.NR_SEQL_CMPS\n",
    "        AND B.TS_INC_VGC = '0001-01-01-00.00.00.000000'\n",
    "        ) as query_psqC10\n",
    "        \"\"\".format(aux_cd_mtdl,aux_cd_rgr,cd_crit_e)\n",
    "    \n",
    "        query_psqC10 = spark.read.format(\"jdbc\") \\\n",
    "                                 .option(\"URL\",URL) \\\n",
    "                                 .option(\"driver\",JCN) \\\n",
    "                                 .option(\"dbtable\",query_psqC10) \\\n",
    "                                 .option(\"user\",DB2_USER) \\\n",
    "                                 .option(\"password\",DB2_PASSWORD) \\\n",
    "                                 .option('KeepAliveTimeout','10') \\\n",
    "                                 .load()  \n",
    "        return query_psqC10\n",
    "    \n",
    "    \n",
    "    elif key == 11:\n",
    "            \n",
    "        query_psqC11 = \"\"\"\n",
    "        (\n",
    "        SELECT\n",
    "        B.CD_TIP_CTU,\n",
    "        B.TX_CTU,\n",
    "        B.IN_CRIT_ATI\n",
    "        FROM\n",
    "        \"\".RGR_INRO_MTDL AS A,\n",
    "        \"\".CMPS_RGR_INRO AS B\n",
    "        WHERE\n",
    "        A.CD_MTDL_ANL_CRD = {0}\n",
    "        AND A.CD_RGR_INRO = {1}\n",
    "        AND B.CD_MTDL_ANL_CRD = A.CD_MTDL_ANL_CRD\n",
    "        AND B.CD_RGR_INRO = A.CD_RGR_INRO\n",
    "        AND B.CD_CRIT_INRO = {2}\n",
    "        AND B.NR_SEQL_CRIT_INRO = {3}\n",
    "        AND B.NR_SEQL_CMPS = {4}\n",
    "        ) as query_psqC11\n",
    "        \"\"\".format(aux_cd_mtdl,aux_cd_rgr,cd_crit_e,gda_nr_seql_crit_loc,gda_nr_seql_cmps)\n",
    "    \n",
    "        query_psqC11 = spark.read.format(\"jdbc\")\\\n",
    "                                 .option(\"URL\",URL) \\\n",
    "                                 .option(\"driver\",JCN) \\\n",
    "                                 .option(\"dbtable\",query_psqC11) \\\n",
    "                                 .option(\"user\",DB2_USER) \\\n",
    "                                 .option(\"password\",DB2_PASSWORD) \\\n",
    "                                 .option('KeepAliveTimeout','10') \\\n",
    "                                 .load()\n",
    "        \n",
    "        return query_psqC11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566b739-312d-4083-94d7-6f7f8d53f115",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PesquisaMetodologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d040fb75-b159-4318-af18-492feab73533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def pesquisaMetodologia(df,psq):\n",
    "        '''\n",
    "        Funcao responsavel por chamar as metodologias, vigente, pendente, histórico e regra pendente\n",
    "        \n",
    "        Arguments:\n",
    "            df {DataFrame} -- dataframe criado a partir da carga do arquivo contendo os registros dos clientes\n",
    "        Keyword Arguments:\n",
    "            None\n",
    "        Returns:\n",
    "            {DataFrame}\n",
    "        See:\n",
    "            funcao acionada: \n",
    "                None\n",
    "            chamada pela funcao:\n",
    "                def RotinaPrincipal\n",
    "        '''\n",
    "        \n",
    "        w=Window.orderBy(lit(1))\n",
    "        \n",
    "        if psq == \"mtld\":\n",
    "            \n",
    "            query_psq = MontaQuery(5)\n",
    "            query_psq = query_psq.withColumn(\"rn\",row_number().over(w)-1)            \n",
    "            \n",
    "            pesquisaMetodologiaMtldDF = df.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            \n",
    "            pesquisaMetodologiaMtldDF = pesquisaMetodologiaMtldDF.join(query_psq,[\"rn\"],\"left\")\\\n",
    "                                                                 .withColumn(\"cd_mtdl_anl_aux\",col(\"CD_MTDL_ANL_CRD\"))\\\n",
    "                                                                 .drop(\"CD_MTDL_ANL_CRD\")\\\n",
    "                                                                 .withColumn(\"qt_reg\",col(\"rn\"))\\\n",
    "                                                                 .drop(col(\"rn\"))\n",
    "            \n",
    "            return pesquisaMetodologiaMtldDF \n",
    "        \n",
    "        if psq == \"vgt\":\n",
    "            \n",
    "            query_psq = MontaQuery(6)\n",
    "            query_psq = query_psq.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            \n",
    "            pesquisaMetodologiaVgtDF = df.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            pesquisaMetodologiaVgtDF = pesquisaMetodologiaVgtDF.join(query_psq,[\"rn\"],\"left\")\\\n",
    "                                                               .withColumn(\"cd_mtdl_anl_aux\",col(\"CD_MTDL_ANL_CRD\"))\\\n",
    "                                                               .drop(\"CD_MTDL_ANL_CRD\")\\\n",
    "                                                               .withColumn(\"qt_reg\",col(\"rn\"))\\\n",
    "                                                               .drop(col(\"rn\"))\n",
    "            \n",
    "            return pesquisaMetodologiaVgtDF\n",
    "        \n",
    "        if psq == \"pnd\":\n",
    "            \n",
    "            query_psq = MontaQuery(7)\n",
    "            query_psq = query_psq.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            \n",
    "            pesquisaMetodologiaPndDF = df.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            pesquisaMetodologiaPndDF = pesquisaMetodologiaPndDF.join(query_psq,[\"rn\"],\"left\")\\\n",
    "                                                               .withColumn(\"cd_mtdl_anl_aux\",col(\"CD_MTDL_ANL_CRD\"))\\\n",
    "                                                               .drop(\"CD_MTDL_ANL_CRD\")\\\n",
    "                                                               .withColumn(\"qt_reg\",col(\"rn\"))\\\n",
    "                                                               .drop(col(\"rn\"))\n",
    "                \n",
    "            return pesquisaMetodologiaPndDF\n",
    "        \n",
    "        if psq == \"hst\":\n",
    "            \n",
    "            query_psq = MontaQuery(8)\n",
    "            query_psq = query_psq.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            \n",
    "            pesquisaMetodologiaHstDF = df.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            pesquisaMetodologiaHstDF = pesquisaMetodologiaHstDF.join(query_psq,[\"rn\"],\"left\")\\\n",
    "                                                               .withColumn(\"cd_mtdl_anl_aux\",col(\"CD_MTDL_ANL_CRD\"))\\\n",
    "                                                               .drop(\"CD_MTDL_ANL_CRD\")\\\n",
    "                                                               .withColumn(\"qt_reg\",col(\"rn\"))\\\n",
    "                                                               .drop(col(\"rn\"))           \n",
    "            \n",
    "            return pesquisaMetodologiaHstDF\n",
    "        \n",
    "        if psq == \"rgr\":\n",
    "            \n",
    "            query_psq = MontaQuery(4)\n",
    "            query_psq = query_psq.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            \n",
    "            pesquisaMetodologiaRgrDF = df.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            pesquisaMetodologiaRgrDF = pesquisaMetodologiaRgrDF.join(query_psq,[\"rn\"],\"left\").drop(\"rn\")\\\n",
    "                                                               .withColumn(\"qt_reg\",F.when(col(\"CONTAGEM_GERAL\").isnull(),lit(0))\\\n",
    "                                                               .otherwise(col(\"CONTAGEM_GERAL\"))\\\n",
    "                                                                          )\\\n",
    "                                                               .drop(col(\"CONTAGEM_GERAL\"))\n",
    "            \n",
    "            return pesquisaMetodologiaRgrDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a725e292-3a79-4aa3-a8ae-6074770e8af5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PesquisaCriterio2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d63d3705-99b2-454e-95f2-b89ceb15098f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def pesquisaCriterio2(df):\n",
    "        '''\n",
    "        Metodo traduzido da subrotina\n",
    "        \n",
    "        Arguments:\n",
    "            df {DataFrame} -- dataframe criado a partir da carga do arquivo contendo os registros dos clientes\n",
    "        Keyword Arguments:\n",
    "            None\n",
    "        Returns:\n",
    "            {DataFrame}\n",
    "        See:\n",
    "            funcao acionada: \n",
    "                None\n",
    "            chamada pela funcao:\n",
    "                def RotinaPrincipal\n",
    "        '''\n",
    "        \n",
    "        w=Window.orderBy(lit(1))\n",
    "        \n",
    "        query_psq  = MontaQuery(11)\n",
    "        query_psq = query_psq.withColumn(\"rn\",row_number().over(w)-1)\n",
    "        \n",
    "        pesquisaCriterio2DF = df.withColumn(\"rn\",row_number().over(w)-1)\\\n",
    "                                .withColumn(\"qt_reg\",col(\"qt_reg\") + 1 )\\\n",
    "                                .withColumn(\"cd_crit\",col(\"aux_cd_crit\"))\\\n",
    "                                .withColumn(\"nr_seql_crit\",col(\"gda_nr_seql_crit_loc\"))\n",
    "        \n",
    "        pesquisaCriterio2DF = pesquisaCriterio2DF.join(query_psq, [\"rn\"], \"left\")\\\n",
    "                                                 .drop(\"rn\")\\\n",
    "                                                 .withColumn(\"cd_tip_ctu\", F.col(\"CD_TIP_CTU\"))\\\n",
    "                                                 .withColumn(\"tx_ctu\",     F.col(\"TX_CTU\"))\\\n",
    "                                                 .withColumn(\"vl_flo_crit\",F.col(\"TX_CTU\"))\\\n",
    "                                                 .withColumn(\"in_crit_atv\",F.col(\"IN_CRIT_ATI\"))\\\n",
    "                                                 .drop(\"IN_CRIT_ATI\")\n",
    "        \n",
    "\n",
    "        \n",
    "        return pesquisaCriterio2DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0832c-4962-4cd5-93ee-949cde1c8db6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PesquisaCriterioPendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ec7cca4f-ec2a-4497-bf38-f741e3b60152",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def pesquisarCriterioPend(df):\n",
    "        '''\n",
    "        Metodo traduzido da rotina\n",
    "        \n",
    "        Arguments:\n",
    "            df {DataFrame} -- dataframe criado a partir da carga do arquivo contendo os registros dos clientes\n",
    "        Keyword Arguments:\n",
    "            None\n",
    "        Returns:\n",
    "            {DataFrame}\n",
    "        See:\n",
    "            funcao acionada: \n",
    "                None\n",
    "            chamada pela funcao:\n",
    "                def RotinaPrincipal\n",
    "        '''\n",
    "        \n",
    "        # constante \n",
    "        \n",
    "        w=Window.orderBy(lit(1))\n",
    "        \n",
    "        # expressao logica\n",
    "        \n",
    "        EXPR_IN_CARREGA_TAB = expr(\"in_ret_bxd = 'S' or gda_in_rgr_atv = 'S' and gda_crit_atv = 'S' \")\n",
    "        \n",
    "        # Inicialização \n",
    "        \n",
    "        query_psq  = MontaQuery(3)\n",
    "        query_psq = query_psq.withColumn(\"rn\",row_number().over(w)-1)\n",
    "        \n",
    "        pesquisarCriterioPendDF = df.withColumn(\"rn\",row_number().over(w)-1)\n",
    "        \n",
    "        \n",
    "        pesquisarCriterioPendDF =  pesquisarCriterioPendDF.join(query_psq, [\"rn\"], \"left\")\\\n",
    "                                                          .drop(\"rn\")\\\n",
    "                                                          .withColumn(\"gda_in_rgr_atv\",  F.col(\"IN_RGR_ATV\"))\\\n",
    "                                                          .drop(\"IN_RGR_ATV\")\\\n",
    "                                                          .withColumn(\"gda_cd_crit\",     F.col(\"CD_CRIT_INRO\"))\\\n",
    "                                                          .drop(\"CD_CRIT_INRO\")\\\n",
    "                                                          .withColumn(\"gda_nr_seql_crit\",F.col(\"NR_SEQL_CRIT_INRO\"))\\\n",
    "                                                          .drop(\"NR_SEQL_CRIT_INRO\")\\\n",
    "                                                          .withColumn(\"gda_cd_tip_ctu\",  F.col(\"CD_TIP_CTU\"))\\\n",
    "                                                          .drop(\"CD_TIP_CTU\")\\\n",
    "                                                          .withColumn(\"gda_tx_ctu\",      F.col(\"TX_CTU\"))\\\n",
    "                                                          .drop(\"TX_CTU\")\\\n",
    "                                                          .withColumn(\"gda_in_crit_atv\", F.col(\"IN_CRIT_ATI\"))\\\n",
    "                                                          .drop(\"IN_CRIT_ATI\")\\\n",
    "                                                          .withColumn(\"in_carregaTab\",   F.when(EXPR_IN_CARREGA_TAB,lit(True))\\\n",
    "                                                                                          .otherwise(lit(False))\\\n",
    "                                                                     )\n",
    "                                     \n",
    "            \n",
    "        \n",
    "        return pesquisarCriterioPendDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0a8d1-a952-4486-b916-f645114615a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PesquisaSelecaoCriterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e4b23cbd-70a5-4bd1-80d3-3217fdec6b01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def pesquisarSeqlCrit(df):\n",
    "        '''\n",
    "        Metodo traduzido da rotina\n",
    "        \n",
    "        Arguments:\n",
    "            df {DataFrame} -- dataframe criado a partir da carga do arquivo contendo os registros dos clientes\n",
    "        Keyword Arguments:\n",
    "            None\n",
    "        Returns:\n",
    "            {DataFrame}\n",
    "        See:\n",
    "            funcao acionada: \n",
    "                None\n",
    "            chamada pela funcao:\n",
    "                def RotinaPrincipal\n",
    "        '''\n",
    "        \n",
    "        # constante \n",
    "        \n",
    "        w=Window.orderBy(lit(1))\n",
    "        \n",
    "        # Inicialização \n",
    "        \n",
    "        query_psq  = MontaQuery(10)\n",
    "        query_psq = query_psq.withColumn(\"rn\",row_number().over(w)-1)\n",
    "        \n",
    "        pesquisarSeqlCritDF = df.withColumn(\"rn\",row_number().over(w)-1)\n",
    "        \n",
    "        \n",
    "        pesquisarSeqlCritDF =  pesquisarSeqlCritDF.join(query_psq, [\"rn\"], \"left\")\\\n",
    "                                                  .withColumn(\"qtd_reg\",lit(1))\\\n",
    "                                                  .withColumn(\"nr_seql_crit\",F.when(col(\"NR_SEQL_CRIT_INRO\").isnull(),lit(0))\\\n",
    "                                                                              .otherwise(col(\"NR_SEQL_CRIT_INRO\"))\\\n",
    "                                                              )\\\n",
    "                                                  .drop(\"NR_SEQL_CRIT_INRO\")\n",
    "        \n",
    "                                                              \n",
    "        return pesquisarSeqlCritDF\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77d3c1-de61-4dc9-98ff-9b79c6db0416",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RotinaPrincipal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b480a0d3-d697-496b-a684-7ce8830c535a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def rotina_Principal(df):\n",
    "        '''\n",
    "        Acionada tem o objetivo chamar as rotinas que pesquisam os critérios e as metodologias.\n",
    "        \n",
    "        Arguments:\n",
    "            df {DataFrame} -- dataframe criado a partir da carga do arquivo contendo os registros dos clientes\n",
    "               \n",
    "        Keyword Arguments:\n",
    "            None\n",
    "        Returns:\n",
    "            {DataFrame}\n",
    "        See:\n",
    "            funcao acionada: \n",
    "                def MontaQuery\n",
    "                def pesquisarCriterioPend\n",
    "                def pesquisaMetodologia\n",
    "            chamada pela funcao:\n",
    "                def FuncPrincipal\n",
    "        '''\n",
    "\n",
    "        #1 Verifica as condições para criação da cod das query\n",
    "        #2 Realiza a montagem das query e a execução no banco de dados retornando um dataframe spark atraves da função MONTAQUERY \n",
    "        #3 IN_MONTAQUERY: Construção dos parametros para as funções de construções e execução das query no banco de dados já formatadas conforme função\n",
    "        #4 MONTAQUERY: Refere-se a função MONTAQUERY onde a mesma formata determinadas query e executa as mesmas no banco de dados o resultado é transformado em dataframe spark \n",
    "        #5 EXPR_IN_PESQUISA_CRITERIO_1_9: Refere-se ao indicador para execução da query com chave 1 mas executando a query de chave 9 \n",
    "        \n",
    "        \n",
    "        # constantes\n",
    "        \n",
    "        w=Window.orderBy(lit(1))\n",
    "\n",
    "        \n",
    "        # expressoes logicas\n",
    "        \n",
    "        EXPR_IN_RET_BXD = expr(\"in_ret_bxd = 'S'\")\n",
    "        EXPR_COD_FUNC_1 = expr(\"cd_fuc = 1\")\n",
    "        EXPR_IN_PESQUISA_CRITERIO_1 = EXPR_COD_FUNC_1 & EXPR_IN_RET_BXD\n",
    "        EXPR_IN_PESQUISA_CRITERIO_1_9 = EXPR_COD_FUNC_1 & ~EXPR_IN_RET_BXD\n",
    "        EXPR_IN_MONTAQUERY_2 = expr(\"cd_fuc = 2\")\n",
    "        EXPR_IN_MONTAQUERY_3 = expr(\"cd_fuc = 3\")\n",
    "        EXPR_IN_MONTAQUERY_4 = expr(\"cd_fuc = 4\")\n",
    "        EXPR_IN_MONTAQUERY_5 = expr(\"cd_fuc = 5\")\n",
    "        EXPR_IN_MONTAQUERY_6 = expr(\"cd_fuc = 6\")\n",
    "        EXPR_IN_MONTAQUERY_7 = expr(\"cd_fuc = 7\")\n",
    "        EXPR_IN_MONTAQUERY_8 = expr(\"cd_fuc = 8\")\n",
    "        EXPR_IN_MONTAQUERY_9 = expr(\"cd_fuc = 9\")\n",
    "        EXPR_IN_MONTAQUERY_10 = expr(\"cd_fuc = 10\")\n",
    "\n",
    "\n",
    "        # inicialização \n",
    "        \n",
    "        rotina_PrincipalDF = df.withColumn(\"Cod_MontaQuery\", F.when(EXPR_IN_MONTAQUERY_2,lit(2))\\\n",
    "                                                              .when(EXPR_IN_MONTAQUERY_3,lit(3))\\\n",
    "                                                              .when(EXPR_IN_MONTAQUERY_4,lit(4))\\\n",
    "                                                              .when(EXPR_IN_MONTAQUERY_5,lit(5))\\\n",
    "                                                              .when(EXPR_IN_MONTAQUERY_6,lit(6))\\\n",
    "                                                              .when(EXPR_IN_MONTAQUERY_7,lit(7))\\\n",
    "                                                              .when(EXPR_IN_MONTAQUERY_8,lit(8))\\\n",
    "                                                              .when(EXPR_IN_MONTAQUERY_9,lit(9))\\\n",
    "                                                              .when(EXPR_IN_MONTAQUERY_10,lit(10))\\\n",
    "                                                              .otherwise(lit(0))\\\n",
    "                                          )\\\n",
    "                               .withColumn(\"Cod_pesquisa_criterio\",F.when(EXPR_IN_PESQUISA_CRITERIO_1_9,lit(9))\\\n",
    "                                                                    .when(EXPR_IN_PESQUISA_CRITERIO_1,lit(1))\\\n",
    "                                                                    .otherwise(lit(0))\\\n",
    "                                          )\\\n",
    "                               .withColumn(\"rn\",row_number().over(w)-1)\n",
    "          \n",
    "        \n",
    "        cod_pesquisa_criterio = rotina_PrincipalDF.limit(1).select(\"Cod_pesquisa_criterio\").collect()[0][\"Cod_pesquisa_criterio\"]\n",
    "        cod_query = rotina_PrincipalDF.limit(1).select(\"Cod_MontaQuery\").collect()[0][\"Cod_MontaQuery\"]\n",
    "        \n",
    "        \n",
    "        if cod_pesquisa_criterio == 1 or cod_pesquisa_criterio == 9:\n",
    "            \n",
    "            QueryMontadaDF = MontaQuery(cod_pesquisa_criterio)\n",
    "            QueryMontadaDF = QueryMontadaDF.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            \n",
    "            rotina_PrincipalDF = rotina_PrincipalDF.join(QueryMontadaDF,[\"rn\"],\"left\")\\\n",
    "                                                   .drop(col(\"rn\"))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        elif cod_query == 2 or cod_query == 4:\n",
    "            \n",
    "            \n",
    "            QueryMontadaDF = MontaQuery(cod_query)\n",
    "            QueryMontadaDF = QueryMontadaDF.withColumn(\"rn\",row_number().over(w)-1)\n",
    "            \n",
    "            rotina_PrincipalDF = rotina_PrincipalDF.join(QueryMontadaDF,[\"rn\"],\"left\")\\\n",
    "                                                   .drop(col(\"rn\"))\n",
    "            \n",
    "        \n",
    "        elif cod_query == 3:\n",
    "            \n",
    "            rotina_PrincipalDF = pesquisarCriterioPend(rotina_PrincipalDF)                                  \n",
    "                                           \n",
    "                                           \n",
    "        elif cod_query == 5:\n",
    "            \n",
    "            rotina_PrincipalDF = pesquisaMetodologia(rotina_PrincipalDF,\"mtld\")\n",
    "            \n",
    "        \n",
    "        elif cod_query == 6:\n",
    "            \n",
    "            rotina_PrincipalDF = pesquisaMetodologia(rotina_PrincipalDF,\"vgt\")\n",
    "            \n",
    "        elif cod_query == 7:\n",
    "            \n",
    "            rotina_PrincipalDF = pesquisaMetodologia(rotina_PrincipalDF,\"pnd\")\n",
    "            \n",
    "        elif cod_query == 8:\n",
    "            \n",
    "            rotina_PrincipalDF = pesquisaMetodologia(rotina_PrincipalDF,\"hst\")\n",
    "            \n",
    "        elif cod_query == 9:\n",
    "            \n",
    "            rotina_PrincipalDF = pesquisarSeqlCrit(rotina_PrincipalDF)\n",
    "        \n",
    "        elif cod_query == 10:\n",
    "            \n",
    "            rotina_PrincipalDF = pesquisaMetodologia(rotina_PrincipalDF,\"rgr\")    \n",
    "            \n",
    "\n",
    "        \n",
    "        return rotina_PrincipalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8ac10d31-c572-41ce-92fd-695aae90708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCERRANDO A SESSÃO \n",
    "\n",
    "%spark cleanup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
